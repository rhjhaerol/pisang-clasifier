{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import Image, display\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Input, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9beae",
   "metadata": {},
   "source": [
    "### Splitting folder into train, test, val folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip this if you've already run it\n",
    "\n",
    "import splitfolders\n",
    "\n",
    "input_folder = \"pisang\" #Enter Input Folder\n",
    "output = \"dataset2\" #Enter Output Folder\n",
    "\n",
    "splitfolders.ratio(input_folder, output=output, seed=1, ratio=(0.6,0.2,0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ef783",
   "metadata": {},
   "source": [
    "#### Check image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfImageNames = ['dataset/train/pisang-kulit-luka/IMG_0003.jpg',\n",
    "                   'dataset/train/pisang-kulit-tidak-luka/IMG_0022.jpg']\n",
    "\n",
    "labels = ['Pisang kulit luka', 'Pisang kulit tidak luka']\n",
    "for i,imageName in enumerate(listOfImageNames):\n",
    "    print(labels[i])\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = cv2.imread(\"dataset/train/pisang-kulit-luka/IMG_0003.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ddef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d1cf5",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b210df",
   "metadata": {},
   "source": [
    "For the documentation of data augment, please follow this link https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3395e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(\n",
    "                    rescale = 1./255,\n",
    "                    shear_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    zoom_range=0.2,\n",
    "                    rotation_range = 20,\n",
    "                    width_shift_range= 0.2,\n",
    "                    height_shift_range= 0.2)\n",
    "\n",
    "validate_data_gen = ImageDataGenerator(\n",
    "                    rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  train_data_gen.flow_from_directory(\n",
    "                        \"dataset2/train\",\n",
    "                        target_size=(128,128),\n",
    "                        batch_size=32,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "validate_data = validate_data_gen.flow_from_directory(\n",
    "                        \"dataset2/val\",\n",
    "                        target_size=(128,128),\n",
    "                        batch_size=32,\n",
    "                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a971c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch, labels_batch in train_data:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189913d",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28624df8",
   "metadata": {},
   "source": [
    "### Follow the link below for more detailed explanation\n",
    "\n",
    "#### Model\n",
    "- CNN : https://medium.com/@draj0718/convolutional-neural-networks-cnn-architectures-explained-716fb197b243 <br>\n",
    "- VGG16 : https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16 | https://keras.io/api/applications/vgg/ <br>\n",
    "- Resnet50 : https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50 | https://keras.io/api/applications/resnet/ <br>\n",
    "- EarlyStopping : https://keras.io/api/callbacks/early_stopping/ <br>\n",
    "- Adam optimizer : https://keras.io/api/optimizers/adam/ | https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam <br>\n",
    "- Metric accuracy : https://keras.io/api/metrics/accuracy_metrics/#accuracy-class <br>\n",
    "- Layers : https://keras.io/api/layers/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bd30bc",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34740a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "modelcnn = Sequential()\n",
    "\n",
    "# 1st layer CNN\n",
    "modelcnn.add(Conv2D(filters=32, kernel_size=5, activation='relu', input_shape=[128,128,3]))\n",
    "modelcnn.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "modelcnn.add(BatchNormalization())\n",
    "# modelcnn.add(Dropout(0.2))\n",
    "\n",
    "# 2nd layer CNN\n",
    "modelcnn.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "modelcnn.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "modelcnn.add(BatchNormalization())\n",
    "# modelcnn.add(Dropout(0.2))\n",
    "\n",
    "# 3rd layer CNN\n",
    "modelcnn.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "modelcnn.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "modelcnn.add(BatchNormalization())\n",
    "# modelcnn.add(Dropout(0.2))\n",
    "\n",
    "# 4th layer CNN\n",
    "modelcnn.add(Conv2D(filters=256, kernel_size=3, activation='relu'))\n",
    "modelcnn.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "modelcnn.add(BatchNormalization())\n",
    "modelcnn.add(Dropout(0.2))\n",
    "\n",
    "modelcnn.add(Flatten())\n",
    "modelcnn.add(Dense(515,activation='relu'))\n",
    "modelcnn.add(Dense(2,activation='softmax'))\n",
    "\n",
    "modelcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8eeabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a visual view of the architecture\n",
    "keras.utils.plot_model(modelcnn, to_file='arsitektur-model/modelcnn.png', show_shapes=True, show_dtype=True, \n",
    "                       show_layer_names=True, expand_nested=True,\n",
    "                       dpi=75, show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ca7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create earlystopping for callback\n",
    "es = EarlyStopping(monitor='val_loss', patience=3, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9180febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "modelcnn.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27281e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "modelcnn.fit(train_data,\n",
    "          verbose=1,\n",
    "          validation_data=validate_data,\n",
    "          batch_size=64,\n",
    "          epochs=15)\n",
    "#           callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe of losses and accuracies of model\n",
    "losses = modelcnn.history.history\n",
    "df_loss = pd.DataFrame(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss.sort_values(by='val_accuracy',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f033411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the performance of model\n",
    "pd.DataFrame(modelcnn.history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.title('Accuracy vs Epoch Plot of the CNN Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26093817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi model\n",
    "loss, accuracy= modelcnn.evaluate(test_data)\n",
    "print(f'Accuracy: {accuracy*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb0e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "modelcnn.save('model/modelcnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf07023",
   "metadata": {},
   "source": [
    "#### #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00508229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "modelcnn2 = Sequential()\n",
    "\n",
    "# 1st layer CNN\n",
    "modelcnn2.add(Conv2D(filters=32, kernel_size=5, activation='relu', input_shape=[128,128,3]))\n",
    "modelcnn2.add(MaxPool2D(2,2))\n",
    "\n",
    "# 2nd layer CNN\n",
    "modelcnn2.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "modelcnn2.add(MaxPool2D(2,2))\n",
    "\n",
    "# 3rd layer CNN\n",
    "modelcnn2.add(Conv2D(filters=62, kernel_size=3, activation='relu'))\n",
    "modelcnn2.add(MaxPool2D(2,2))\n",
    "\n",
    "# 4th layer CNN\n",
    "modelcnn2.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "modelcnn2.add(MaxPool2D((2,2), strides=2))\n",
    "modelcnn2.add(Dropout(0.3))\n",
    "\n",
    "modelcnn2.add(Flatten())\n",
    "modelcnn2.add(Dense(512,activation='relu'))\n",
    "modelcnn2.add(Dense(2,activation='softmax'))\n",
    "\n",
    "modelcnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn2.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61256ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "modelcnn2.fit(\n",
    "      train_data,\n",
    "      steps_per_epoch=len(train_data),\n",
    "      epochs=15,\n",
    "      validation_data=validate_data,\n",
    "      validation_steps=len(validate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a850529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the performance of model\n",
    "pd.DataFrame(modelcnn2.history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.title('Accuracy vs Epoch Plot of the CNN Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn2.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e355d4",
   "metadata": {},
   "source": [
    "### VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape=(128, 128, 3), weights='imagenet', include_top=False)\n",
    "vgg.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fdcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our layers - you can add more if you want\n",
    "inputs = keras.Input(shape=(128, 128, 3))\n",
    "X = vgg(inputs,training=False)\n",
    "X = MaxPool2D()(X)\n",
    "X = Flatten()(X)\n",
    "X = Dense(128, activation='relu')(X)\n",
    "X = Dense(2, activation='softmax')(X)\n",
    "\n",
    "# create a model object\n",
    "modelvgg16 = Model(inputs=inputs, outputs=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the structure of the model\n",
    "modelvgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d74a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a visual view of the architecture\n",
    "keras.utils.plot_model(modelvgg16, to_file='arsitektur-model/modelvgg16.png', show_shapes=True, show_dtype=True, \n",
    "                       show_layer_names=True, expand_nested=True, \n",
    "                       dpi=75, show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e158d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "modelvgg16.compile(optimizer='adam',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8513600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "modelvgg16.fit(train_data,\n",
    "             validation_data=validate_data,\n",
    "             epochs=15,\n",
    "             steps_per_epoch=len(train_data),\n",
    "             validation_steps=len(test_data),\n",
    "#              callbacks=[es]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deff39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe of losses and accuracies of model\n",
    "losses = modelvgg16.history.history\n",
    "df_loss = pd.DataFrame(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28877ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss.sort_values(by='val_accuracy',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the performance of model\n",
    "pd.DataFrame(modelvgg16.history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.title('Accuracy vs Epoch Plot of the VGG16 Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d59fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi model\n",
    "loss, accuracy= modelvgg16.evaluate(test_data)\n",
    "print(f'Accuracy: {accuracy*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936df699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "modelvgg.save('model/modelvgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7d5d5",
   "metadata": {},
   "source": [
    "### ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84fe7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add preprocessing layer to the front of VGG\n",
    "rsnet = ResNet50(input_shape=(150, 150, 3), weights='imagenet', include_top=False)\n",
    "# don't train existing weights\n",
    "for layer in rsnet.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "X = MaxPool2D()(rsnet.output)\n",
    "X = Flatten()(X)\n",
    "X = Dense(512, activation='relu')(X)\n",
    "X = Dense(2, activation='softmax')(X)\n",
    "\n",
    "# create a model object\n",
    "modelresnet50 = Model(inputs=rsnet.input, outputs=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f79f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the structure of the model\n",
    "modelresnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb2f7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a visual view of the architecture\n",
    "keras.utils.plot_model(modelresnet50, to_file='arsitektur-model/modelresnet50.png', show_shapes=True, show_dtype=True, \n",
    "                       show_layer_names=True, expand_nested=True,\n",
    "                       dpi=75, show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75c3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "modelresnet50.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924818b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "modelresnet50.fit(train_data,\n",
    "              validation_data=validate_data,\n",
    "              epochs=15,\n",
    "              steps_per_epoch=len(train_data),\n",
    "              validation_steps=len(validate_data),\n",
    "#               callbacks=[es]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fd2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe of losses and accuracies of model\n",
    "losses = modelresnet50.history.history\n",
    "df_loss = pd.DataFrame(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss.sort_values(by='val_accuracy',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f046c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the performance of model\n",
    "pd.DataFrame(modelresnet50.history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.title('Accuracy vs Epoch Plot of the VGG16 Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92051ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi model\n",
    "loss, accuracy= modelresnet50.evaluate(test_data)\n",
    "print(f'Accuracy: {accuracy*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelresnet50.save('model/modelresnet50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce70606",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24d4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names =  [\"Pisang Kulit Luka\", \"Pisang Kulit Tidak Luka\"]\n",
    "\n",
    "image_path = \"dataset/test/pisang-kulit-tidak-luka/IMG_0034.jpg\"\n",
    "new_img = image.load_img(image_path, target_size=(150, 150))\n",
    "img = image.img_to_array(new_img)/255\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "images = np.vstack([img])\n",
    "\n",
    "prediction = model.predict(images, batch_size=10)\n",
    "predictions = np.argmax(prediction,axis=1)\n",
    "\n",
    "print('prediksi: {}'.format(class_names[predictions[0]]))\n",
    "print('persentase prediksi: {:.2f} %'.format(np.max(prediction)*100))\n",
    "print('\\n')\n",
    "for i in range(len(class_names)):\n",
    "    print('prediksi:\\t{}'. format(class_names[i]))\n",
    "    print(\"persentase:\\t{:.2f} %\".format(prediction[0][i]*100))\n",
    "\n",
    "plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad4003",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For load the model you can use the code\n",
    "from keras.models import load_model \n",
    "model = load_model('model/modelcnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29067aa",
   "metadata": {},
   "source": [
    "### Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to recreate our test generator with shuffle = false\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        \"dataset2/test\",\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = test_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = modelcnn2.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccaf0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# create confusion matrix\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "\n",
    "print('Classification Report\\n')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9b0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Menampilkan confusion matrix menggunakan heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Prediksi\")\n",
    "plt.ylabel(\"Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
